prac 6

from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.metrics import accuracy_score

iris = load_iris()
X = iris.data
y = iris.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a base classifier 
base_classifier = DecisionTreeClassifier(random_state=42)

# Create a BaggingClassifier with the base classifier
bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)

# Train the BaggingClassifier on the training data
bagging_classifier.fit(X_train, y_train)

# Make predictions on the test data
y_pred = bagging_classifier.predict(X_test)

# Evaluate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')





# AML Practical-7

from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_iris
from sklearn.metrics import accuracy_score

iris = load_iris()
X = iris.data
y = iris.target
# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a base classifier (KNN in this case)
base_classifier = KNeighborsClassifier(n_neighbors=3)

# Create a BaggingClassifier with the base classifier
bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)

# Train the BaggingClassifier on the training data
bagging_classifier.fit(X_train, y_train)

# Make predictions on the test data
y_pred = bagging_classifier.predict(X_test)

# Evaluate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')



# AML Practical-8

from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

# Load the iris dataset
iris = load_iris()
X = iris.data
y = iris.target

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)

# Create a base classifier
base_classifier = DecisionTreeClassifier(random_state=42)

# Experiment with different sample sizes
sample_sizes = [0.5, 0.7, 0.9]
accuracies = []

# Iterate over different sample sizes
for sample_size in sample_sizes:
# Create a BaggingClassifier with the base classifier and specified sample size
bagging_classifier = BaggingClassifier(base_classifier,n_estimators=10,max_samples=sample_size,random_state=42)

# Train the BaggingClassifier on the training data
bagging_classifier.fit(X_train, y_train)

# Make predictions on the test data
y_pred = bagging_classifier.predict(X_test)
    
# Evaluate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
accuracies.append(accuracy)
print(f'Sample Size: {sample_size}, Accuracy: {accuracy:.2f}')

# Plot the results
plt.plot(sample_sizes, accuracies, marker='o')
plt.title('Bagging Sample Size vs Classification Accuracy')
plt.xlabel('Sample Size')
plt.ylabel('Accuracy')
plt.show()






























